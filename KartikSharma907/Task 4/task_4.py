# -*- coding: utf-8 -*-
"""Task 4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lCC8ZbUvGvXztz0FtSKbQtt1VxBg555_
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

names=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']
dataset = pd.read_csv("/content/housing (task4).csv",delim_whitespace=True, names=names)
dataset = dataset.dropna()
dataset.head(5)

corrMatrix = dataset.corr().round(2)
sns.set(rc={'figure.figsize':(12,9)})
sns.heatmap(corrMatrix, annot=True)
plt.show()

array = dataset.values
X = array[:,0:13]
y = array[:,13]

#Scaling the data using Standard scaler
#scaler = StandardScaler().fit(X)
#rX = scaler.fit_transform(X)
#print(rX)

#Scaling the data using MinMax scaler

scaler2 = MinMaxScaler(feature_range=(0, 1))
rX2 = scaler2.fit_transform(X)
np.set_printoptions(precision=4)
print(rX2[0:1,:])

validation_size = 0.20
seed = 3
X_train, X_validation, y_train, y_validation = train_test_split(rX, y,test_size=validation_size, random_state=seed)

models = []
models.append((' LR ', LinearRegression()))
models.append((' LASSO ', Lasso()))
models.append((' EN ', ElasticNet()))
models.append((' KNN ', KNeighborsRegressor()))
models.append((' CART ', DecisionTreeRegressor()))
models.append((' SVR ', SVR()))

results = []
name = []

for name, model in models:
    kfold = KFold(n_splits=3, random_state=2, shuffle=True)
    cv_results = cross_val_score(
        model, X_train, y_train, cv=kfold, scoring='r2')
    results.append(cv_results)
    names.append(name)
    msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
    print(msg)

#Comparing Models

fig = plt.figure()
fig.suptitle(' Algo Comparison ')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()

model = DecisionTreeRegressor(max_depth=20)
model.fit(X_train, y_train)

predictions = model.predict(X_validation)
print(r2_score(y_validation, predictions))

scaler = StandardScaler().fit(X_train)
rescaledX = scaler.transform(X_train)
model = GradientBoostingRegressor(random_state=seed, n_estimators=100)
model.fit(rescaledX, y_train)
# transform the validation dataset
rescaledValidationX = scaler.transform(X_validation)
predictions = model.predict(rescaledValidationX)
print(r2_score(y_validation, predictions))